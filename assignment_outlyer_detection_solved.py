# -*- coding: utf-8 -*-
"""Assignment_outlyer_detection_solved.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1rxWz8cL04hfHIgSvEOr1uViuY_OwlbDM

# Use Case: Detecting Intrusions as Outlier

## Task: detect network intrusions

Contest: KDD-Cup http://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html

NOTE: we are useing only a subset of the original data

Data and full task description: http://kdd.ics.uci.edu/databases/kddcup99/task.html
"""

#download data
#get the data
!git clone https://github.com/keuperj/DATA.git

"""## Task I: Supervised Classification

Use the known tools like Pandas, Numpy, Scikit-Learn

* read the training data in '''DATA/outlier_train_data.csv'''
* clean the data
* do a first data exploration
* train a supervised ML model to classify the different network types
* evaluate the model on '''DATA/outlier_test_data.csv'''
"""

import pandas as pd
    
train = pd.read_csv("DATA/outlier_train_data.csv")

train.isna().all().all()

train.info()

train.head(10)

train.describe()

import numpy as np

X_train = np.array(train)[:,4:-1]
y_train = np.array(train)[:,-1]

from sklearn import preprocessing

le = preprocessing.LabelEncoder()
le.fit(y_train)
list(le.classes_)

ynum = le.transform(y_train)

ynum   # 11 signifies normal

import matplotlib.pyplot as plt

plt.hist(ynum)

y_train = ynum==11
y_train = y_train.astype(int)

plt.hist(y_train, 2)

# Random Forest classifier training

from sklearn.ensemble import RandomForestClassifier

rf = RandomForestClassifier()
rf.fit(X_train, y_train)

# Training accuracy

rf.score(X_train, y_train)

from sklearn.metrics import confusion_matrix

predict = rf.predict(X_train)
confusion_matrix(y_train, predict)

plt.plot(rf.feature_importances_)

test = pd.read_csv("DATA/outlier_test_data.csv", header=None)

test.isna().all().all()

X_test = np.array(test)[:,4:-1]
y_test = np.array(test)[:,-1]

y_test = y_test=='normal.'
y_test = y_test.astype(int)

plt.hist(y_test, 2)

# Test data classification accuracy

rf.score(X_test, y_test)

predict_test = rf.predict(X_test)
confusion_matrix(y_test, predict_test)

"""## Task II: Intrusions as Outlier

Use the train data WITHOUT the lables and train a [Isolation Forest](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.IsolationForest.html).

* check and plot statistics of the isolation values
* find a threshold to select outliers
* evaluate this approach with the test data
"""

from sklearn.ensemble import IsolationForest

If = IsolationForest(random_state=0).fit(X_train)
pred_if = If.predict(X_test)

confusion_matrix(y_test, pred_if)

plt.hist(pred_if)
plt.hist(y_test, color='r')

"""## Assignment: Intrusion detection with Auto Encoders

## Build your own AE on the train data
We use the Kereas Deep Learning library (https://keras.io/) to build the neural networks.

* how many layers should there be in en- and decoder?
* how large should in- and output layers be?
* how large should the latent space be?
* what is a good threshold to find outliers...?
* evaluate your approach against the test set.
"""

col_names = ["1","protocol_type","service","flag","5",
    "6","7","8","9","10","11",
    "12","13","14","15","16",
    "17","18","19","20",
    "21","22","23","24","25",
    "26","27","28","29",
    "30","31","32","33",
    "34","35","36",
    "37","38","39",
    "40","41","label"]
    
train_k = pd.read_csv("DATA/outlier_train_data.csv", header=None, names=col_names)
test_k = pd.read_csv("DATA/outlier_test_data.csv", header=None, names=col_names)
xtrain = train_k.drop(['protocol_type', 'service', 'flag', 'label'], axis=1)
xtest = test_k.drop(['protocol_type', 'service', 'flag', 'label'], axis=1)

from tensorflow import keras
from tensorflow.keras import layers
from matplotlib import pyplot as plt
from keras.layers import Input
from keras.layers import Dense
from keras.models import Model


input_dim = xtrain.shape[1]
encoding_dim = 38

# Building the nueral network and setting "Learning rate"

input_layer = Input(shape=(input_dim, ))
encoder = Dense(encoding_dim, activation="relu")(input_layer)
output_layer = Dense(input_dim, activation='softmax')(encoder)
autoencoder = Model(inputs=input_layer, outputs=output_layer)
autoencoder.compile(optimizer='adam', loss='mean_squared_error',metrics=['accuracy'])
autoencoder.summary()

# Training the model on training dataset

history = autoencoder.fit(xtrain, xtrain, epochs=10,validation_data=(xtest, xtest)).history

# Predicting target attribute on test dataset

test_results = autoencoder.evaluate(xtest, xtest, verbose=1)
print(f'Test results - Loss: {test_results[0]} - Accuracy: {test_results[1]}%')

# Calculating reconstruction error 

predictions = autoencoder.predict(xtest)
train_mae_loss = np.mean(np.abs(predictions - xtest), axis=1)
threshold = np.max(train_mae_loss)
print("Reconstruction error threshold: ", threshold)

plt.plot(xtest)
plt.plot(predictions)
plt.show()